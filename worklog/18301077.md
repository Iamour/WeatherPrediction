# 日志

by 18301077-童路勤

## 2020.6.30

### 上午

- Ubuntu上jdk1.8的安装：使用的是apt install openjdk-8-jdk，然后了解了jdk和openjdk的区别，重新在官网下载了Oracle jdk并安装。在一次重启中，wmware虚拟机黑屏，根据之前的解决方案，netsh winsock reset、移除虚拟机并重新添加、重启后问题解决。
- spark集群：粗略的看了一下要求发现需要两个子节点，暂时跳过
- flask安装：使用
   
       pip install flask -i https://pypi.tuna.tsinghua.edu.cn/simple 
    
    安装完成，并成功运行了 https://dormousehole.readthedocs.io/en/latest/ 中文文档入门教程中的helloworld 程序
- 官网下载 tomcat 9.0.36 zip 包，并根据自带 RUNING.txt 的说明设置 CATALINA_HOME 环境变量，最后运行 startup.bat 成功启动tomcat，运行 shutdown.bat 成功关闭tomcat。

### 下午

配置Ubuntu下的Spark/Hadoop：

- 起初直接使用vmware自带的共享文件夹来传输压缩包，发现无法使用，下载WinSCP连接Ubuntu虚拟机，最后连接成功。
- 使用windows系统编辑好bash脚本，传输到Ubuntu中，执行中出现file not found，发现是Windows的行尾\r\n问题，使用vim转换后成功。
- 运行spark时报错，经查是输入错误。错误改正后，发现访问拒绝，推测是远程登录有问题，暂未找到原因。

## 2020.7.1

### 上午

- 从ubuntu文档、菜鸟教程等地方学习了基本的linux指令，如export等的作用，了解了环境变量的写法。再根据spark/hadoop官网以及文档重新进行配置。遇到了Call to localhost/127.0.0.1:9000 failed on connection exception: java.net.ConnectExcept报错，经查是NameNode进程没有启动，启动后正常，又遇到fs-put无法加载主类报错，正在查找原因。

### 下午

- 查阅了hadoop fs指令的用法，发现上午的fs-put为指令错误，应为fs -put。然后运行hadoop测试程序时系统卡死，重启后打开资源监视器发现为内存不足。调整VMware的cpu核数和内存大小后运行成功。
- 运行pyspark时提示找不到python，发现Ubuntu下默认为python3，pyspark调用的是python，最后使用

       sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 150

   将默认的python3命令改为python，运行成功并筛选了初步的csv数据。
- 参照spark官网的quick start，了解了如何使用pyspark进行数据处理
- 初步了解时间序列分析

## 2020.7.2

### 上午

- 学习使用了pandas、statsmodels等库的API，尝试构建ARIMA模型，但效果不理想。需要继续理解模型的含义。

### 下午

- 使用初步构建的ARIMA模型对数据进行了预测。
- 暂时使用pmdarima库构建了简单的ARIMA模型，计划将接口设计好后使用statsmodels等库进行更详细的模型设计。

## 2020.7.3

### 上午

- 实现模型的接口类
- 继续研究ARIMA模型

### 下午

- 完成了ARIMA模型的demo，手动ARIMA和自动ARIMA，加载模型，传入日期，返回预测值并保存为csv文件。
- ARIMA模型效果十分一般，只能有大体趋势，mse在20-60左右，参数的取值还不太明确，需要进一步学习。

## 2020.7.4

- 尝试改进模型，没有结果

## 2020.7.5

- 继续改进模型。使用的是1980-01-01到2010-01-01的全部温度数据，建立ARIMA模型，发现预测MSE过高，预测值之间没有明显波动，呈直线，尝试使用Auto-ARIMA自动调参仍然无法解决，尝试使用季节性分解，仍无效果。想到使用历年01-01的数据，但感觉仅30多个数据无法得到有效信息，网络上已有的ARIMA预测也没有按年划分数据的例子，也无法解释“用历年02-29的数据预测今年02-29，”，因此很困惑。
- 优化了调用接口函数

## 2020.7.6

- 尝试使用历年当天数据进行ARIMA预测。
- 尝试新的模型，如循环神经网络中的LSTM，以及fbprophet。安装fbprophet时，直接pip会报错，经过查找资料得知使用conda进行安装即可，之后安装成功。学习并简单实现了基于Keras的LSTM算法，在验证集上已有效果，但还不清楚如何进行“预测”，即给定新的时间点，得到预测值，而不是验证集中的时间点。

## 2020.7.7

- 学习LSTM的单变量预测，设计了一个简单的LSTM网络进行训练，但效果不理想，mse=30+，但效果比之前的ARIMA的straight line要好。计划继续学习LSTM网络的结构和参数调整，以及对数据进行预处理等
- 对模型选择产生了一些疑问，目前有以下方案：
  - 对30*365天全年的数据进行ARIMA建模，直接预测7天数据。但效果不理想，几乎straight line，数据之间的波动大约0.2/0.5，可能是pq参数问题。需要3个模型分别对应max/min/avg
  - 对历年某天的数据进行ARIMA建模，得到预测值。预测7天数据时，分别对每天进行上述建模和预测，但时间开销大，7天*3个值，需要21个模型，当然也可以提前存储至数据库
  - 对30*365天全年的数据进行LSTM建模，直接通过之前x天数据预测之后7天数据，目前效果还不理想，需要继续学习。多变量预测下只需1个模型
  - 其他时间序列模型...
- 完成了单变量LSTM的训练/预测python接口，计划学习并实现多变量LSTM，在此基础上尽快优化模型

## 2020.7.8

- 完成了ARIMA模型的接口，作为保守方案
- 继续学习LSTM并调节网络结构和超参数，以获得更好的预测效果
- 在训练LSTM网络时发现loss下降瓶颈，归一化loss下降到0.04左右，原始mse下降到30左右，就难以继续下降，设置更大的模型就会出现过拟合，但过拟合状态下，在训练集上的原始mse已经降到1了，但在训练集上做单独预测效果仍不是很好

## 2020.7.9

- 暂时停止模型研究，选择一个普通的参数，完成了LSTM训练和预测的接口，计划进行多个城市数据模型的训练
- 学习pyspark API，根据观测站编号，使用spark成功提取了ghcn的某年数据文件中的部分观测站的数据

## 2020.7.10

- 编写了python脚本并submit到spark上，从每年的数据文件中筛选出31个省会城市的气温数据，之后对数据进行合并，最终得到每个省会城市历年气温的 *.csv 文件，过程中出现
  
      WARN MemoryStore: Not enough space to cache rdd_1627_8 in memory! (computed 25.6 MiB so far)

  查阅资料得知是spark默认内存限制较小，通过在 /conf/spark-defaults.conf 设置合适的 `spark.driver.memory` 以及 `spark.executor.memory` 后问题解决

- 得到的数据中，部分观测站的数据缺失严重，又筛选了一些地区的数据作为备选

- 学习了spark、pandas有关日期格式转换的API